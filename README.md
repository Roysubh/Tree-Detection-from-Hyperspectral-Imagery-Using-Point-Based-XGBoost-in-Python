ğŸŒ² Tree Detection from Hyperspectral Imagery Using Point-Based XGBoost in Python

ğŸ“„ Overview:
This project presents a robust and efficient approach for tree canopy detection using high-resolution hyperspectral imagery and a point-based XGBoost classification workflow implemented in Python.

The method integrates the spectral richness of hyperspectral data (~1 m resolution) with the power of XGBoost to distinguish tree vs. non-tree classes with high accuracy. Training samples were manually digitized in QGIS and exported as CSV points, forming the foundation for model training and evaluation.

The complete pipeline includes data preprocessing, feature extraction, model training, raster classification, accuracy assessment, and export of final outputs in multiple formats.

ğŸ“Š Project Details:
| Attribute           | Details                                                                     |
| ------------------- | --------------------------------------------------------------------------- |
| **Title**           | Tree Canopy Mapping from Hyperspectral Imagery Using Point-Based XGBoost    |
| **Imagery Source**  | NEON Surface Directional Reflectance (Hyperspectral)                        |
| **Platform**        | NEON AOP (Airborne Observation Platform)                                    |
| **Resolution**      | \~1 m                                                                       |
| **Year of Imagery** | 2014 (JERC Site)                                                            |
| **Sample Type**     | Point-based (Tree/Non-Tree), digitized in QGIS                              |
| **Model**           | XGBoost (Scikit-learn + XGBoost)                                            |
| **Programming**     | Python                                                                      |
| **Outputs**         | GeoTIFF (classified map), CSV (spectral signatures), Pickle (trained model) |
| **Validation**      | Accuracy, RMSE, RÂ² Score, MBE, MAE                                          |

âš™ï¸ Dependencies:
      Install via pip or conda:pip install geopandas rasterio xgboost scikit-learn numpy matplotlib shapely joblib pandas

| Library      | Purpose                                              |
| ------------ | ---------------------------------------------------- |
| geopandas    | Handling shapefiles & point datasets                 |
| rasterio     | Reading/writing raster imagery                       |
| scikit-learn | Preprocessing, metrics, evaluation                   |
| xgboost      | Training & prediction                                |
| numpy        | Numerical operations                                 |
| pandas       | Tabular dataset handling                             |
| matplotlib   | Visualization (classification maps, spectral curves) |
| shapely      | Geometry processing                                  |
| joblib       | Model persistence (save/load)                        |

ğŸš€ Workflow:graph TD
A[ğŸ¯ Define Objective] --> B[ğŸ›°ï¸ Load Hyperspectral Image]
B --> C[ğŸ“‰ Preprocess & Handle Nodata]
C --> D[ğŸ§­ Digitize Training Points in QGIS]
D --> E[ğŸ’¾ Export Points as CSV]
E --> F[ğŸ“¥ Extract Pixel Spectra]
F --> G[ğŸ§  Train XGBoost Model + Tuning]
G --> H[ğŸ—ºï¸ Classify Entire Image]
H --> I[ğŸ§¹ Post-process & Validate]
I --> J[ğŸ“¤ Export GeoTIFF + CSV + Model]
J --> K[ğŸ“Š Evaluate Accuracy & Metrics]

ğŸ“Œ Model Parameters:
| Parameter             | Range/Value | Description                   |
| --------------------- | ----------- | ----------------------------- |
| **n\_estimators**     | 1000â€“2000   | Number of boosting rounds     |
| **max\_depth**        | 8â€“12        | Maximum tree depth            |
| **learning\_rate**    | 0.01â€“0.2    | Step size shrinkage           |
| **subsample**         | 0.6â€“1.0     | Fraction of samples per tree  |
| **colsample\_bytree** | 0.6â€“1.0     | Fraction of features per tree |
| **random\_state**     | 42          | Reproducibility               |

ğŸ“ˆ Evaluation Metrics:
| Metric   | Value  | Description                                                   |
| -------- | ------ | ------------------------------------------------------------- |
| Accuracy | 0.9355 | \~93.6% of pixels classified correctly                        |
| RMSE     | 0.20   | Average magnitude of error                                    |
| RÂ² Score | \~0.80 | \~80% of variance explained                                   |
| MBE      | 0.032  | Slight positive bias (minor overestimation)                   |
| MAE      | 0.065  | Average absolute difference between prediction & ground truth |

ğŸ“¦ Final Outputs:
| Output Type        | Format  | Description                             |
| ------------------ | ------- | --------------------------------------- |
| **Classified Map** | GeoTIFF | Binary raster: 1 = Tree, 0 = Non-Tree   |
| **Spectral Data**  | CSV     | Reflectance values for training samples |
| **Trained Model**  | .pkl    | Serialized XGBoost model for inference  |

ğŸŒˆ Why XGBoost + Hyperspectral Data?
      Hyperspectral Data:
        Hundreds of narrow spectral bands capture subtle surface properties
        Enables vegetation vs. non-vegetation separation with high precision
        ~1 m resolution supports fine-scale canopy mapping
      XGBoost Classifier:
        Handles high-dimensional data efficiently
        Built-in regularization prevents overfitting
        Performs implicit feature selection
        Scalable and faster than many traditional ML methods
      Combined Strength:
        Hyperspectral richness fused with XGBoostâ€™s learning capacity yields a scalable, accurate, and computationally efficient solution for tree canopy mapping.

ğŸŒ Data Source:
      Platform: NEON AOP (Airborne Observation Platform)
      Dataset: NEON Surface Directional Reflectance (NEON_D_HYPERSPECTRAL)
      Resolution: ~1m
      Year: 2014 (JERC Site)

ğŸ“Œ Conclusion:
      This project demonstrates the potential of combining hyperspectral imagery with XGBoost classification for tree canopy mapping.
      With carefully prepared reflectance datasets, labeled training samples, and optimized hyperparameters, we achieved:
      âœ… Accuracy: 93.55%
      âœ… RMSE: 0.20
      âœ… RÂ²: ~0.80
      âœ… MBE: 0.032
      âœ… MAE: 0.065
      The resulting outputsâ€”classified GeoTIFF, spectral dataset, and trained modelâ€”are applicable for ecological monitoring, forest inventory, and environmental change detection.

ğŸŒ Applications:
      Vegetation / canopy cover mapping
      Land use / land cover (LULC) classification
      Crop health and stress monitoring
      Environmental change analysis

ğŸ‘¤ Author: Subham Roy
